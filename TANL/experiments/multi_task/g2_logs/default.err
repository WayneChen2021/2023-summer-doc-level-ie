/home/zc272/2023-summer-doc-level-ie/TANL/experiments/multi_task/g2_environments/default/utils.py:15: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if episodes_string is not None and episodes_string is not '':
/home/zc272/.conda/envs/TANL2/lib/python3.11/site-packages/transformers/models/t5/tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.
For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.
- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.
- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.
- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.
  warnings.warn(
Episode 0 (1 episodes total)
Output directory: experiments/muc_multitask-t5-base-ep38-len512-b1-train/episode0
Using model t5-base
Tree structure is not satisfied! Dropping annotation ([('template entity',)], 105, 117)
Token indices sequence length is longer than the specified maximum sequence length for this model (591 > 512). Running this sequence through the model will result in indexing errors
Max sequence length is 512 but the longest input sequence is 2056 long
Max sequence length is 512 but the longest output sequence is 2047 long
Max sequence length is 512 but the longest input sequence is 2057 long
Max sequence length is 512 but the longest output sequence is 2047 long
Max sequence length is 512 but the longest input sequence is 1681 long
Loaded 1515 sentences for split train of mucevent_argument
Traceback (most recent call last):
  File "/home/zc272/2023-summer-doc-level-ie/TANL/experiments/multi_task/g2_environments/default/run.py", line 332, in <module>
    main()
  File "/home/zc272/2023-summer-doc-level-ie/TANL/experiments/multi_task/g2_environments/default/run.py", line 225, in main
    dataset = load_dataset(
              ^^^^^^^^^^^^^
  File "/home/zc272/2023-summer-doc-level-ie/TANL/experiments/multi_task/g2_environments/default/datasets.py", line 53, in load_dataset
    return DATASETS[dataset_name](
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zc272/2023-summer-doc-level-ie/TANL/experiments/multi_task/g2_environments/default/base_dataset.py", line 90, in __init__
    self.examples = self.load_data(mode=mode, seed=seed)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zc272/2023-summer-doc-level-ie/TANL/experiments/multi_task/g2_environments/default/base_dataset.py", line 175, in load_data
    examples += self.load_data_single_split(split, seed=seed)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zc272/2023-summer-doc-level-ie/TANL/experiments/multi_task/g2_environments/default/datasets.py", line 2145, in load_data_single_split
    examples += self.yield_single_document(x['id'], x['tokens'], x, same_input_output_trigs)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zc272/2023-summer-doc-level-ie/TANL/experiments/multi_task/g2_environments/default/datasets.py", line 2090, in yield_single_document
    input_parts += self.handle_multi_trig(x, tokens, docid)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/zc272/2023-summer-doc-level-ie/TANL/experiments/multi_task/g2_environments/default/datasets.py", line 2070, in handle_multi_trig
    raise e      
    ^^^^^^^
  File "/home/zc272/2023-summer-doc-level-ie/TANL/experiments/multi_task/g2_environments/default/datasets.py", line 2061, in handle_multi_trig
    relations = [
                ^
  File "/home/zc272/2023-summer-doc-level-ie/TANL/experiments/multi_task/g2_environments/default/datasets.py", line 2064, in <listcomp>
    ], head=[ent for ent in entities if ent.id == y['head']][0], tail=triggers[0]
            ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^
IndexError: list index out of range
